{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O46pi1gfxla_"
      },
      "outputs": [],
      "source": [
        "## Inception Block\n",
        "\n",
        "def inception_block(x, filters):\n",
        "  tower1 = Conv2D(filters[0], (1, 1), padding = 'same', activation = 'relu')(x)\n",
        "  tower1 = Conv2D(filters[1], (3, 3), padding = 'same', activation = 'relu')(tower1)\n",
        "\n",
        "  tower2 = Conv2D(filters[2], (1, 1), padding = 'same', activation = 'relu')(x)\n",
        "  tower2 = Conv2D(filters[3], (5, 5), padding = 'same', activation = 'relu')(tower2)\n",
        "\n",
        "  tower3 = MaxPolling2D((3, 3),strides = (1, 1) padding = 'same')(x)\n",
        "  tower3 = Conv2D(filters[4], (1, 1), padding = 'same', activation = 'relu')(tower3)\n",
        "\n",
        "  output = concatenate([tower1, tower2, tower3], axis = 3)\n",
        "  return output\n",
        "\n",
        "\n",
        "\n",
        "  # Build the Inception model\n",
        "def inception(input_shape, num_classes):\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    x = Conv2D(64, (3, 3), padding='same', activation='relu')(inputs)\n",
        "    x = MaxPooling2D((2, 2))(x)\n",
        "\n",
        "    x = inception_block(x, filters=[64, 96, 128, 16, 32])\n",
        "    x = inception_block(x, filters=[128, 128, 192, 32, 96])\n",
        "    x = MaxPooling2D((2, 2))(x)\n",
        "\n",
        "    x = inception_block(x, filters=[192, 96, 208, 16, 48])\n",
        "    x = inception_block(x, filters=[160, 112, 224, 24, 64])\n",
        "    x = inception_block(x, filters=[128, 128, 256, 24, 64])\n",
        "    x = inception_block(x, filters=[112, 144, 288, 32, 64])\n",
        "    x = MaxPooling2D((2, 2))(x)\n",
        "\n",
        "    x = inception_block(x, filters=[256, 160, 320, 32, 128])\n",
        "    x = inception_block(x, filters=[256, 160, 320, 32, 128])\n",
        "    x = inception_block(x, filters=[384, 192, 384, 48, 128])\n",
        "\n",
        "    x = AveragePooling2D((4, 4))(x)\n",
        "    x = Flatten()(x)\n",
        "    outputs = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the Inception model\n",
        "model = inception(input_shape=(224, 224, 3), num_classes=17)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Print a summary of the model\n",
        "model.summary()\n",
        "\n",
        "# Train\n",
        "model.fit(x_train, y_train, batch_size=64, epochs=5, verbose=1,validation_split=0.2, shuffle=True)\n"
      ],
      "metadata": {
        "id": "h7feng1r1dih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pretrained"
      ],
      "metadata": {
        "id": "qC74MQrb1Gqz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# download the data from g drive\n",
        "\n",
        "import gdown\n",
        "url = \"https://drive.google.com/file/d/12jiQxJzYSYl3wnC8x5wHAhRzzJmmsCXP/view?usp=sharing\"\n",
        "file_id = url.split(\"/\")[-2]\n",
        "print(file_id)\n",
        "prefix = 'https://drive.google.com/uc?/export=download&id='\n",
        "gdown.download(prefix+file_id, \"catdog.zip\")"
      ],
      "metadata": {
        "id": "75f1RyAc1DZ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "\n",
        "# Set the path to your training and validation data\n",
        "train_data_dir = '/content/train'\n",
        "validation_data_dir = '/content/validation'\n",
        "\n",
        "# Set the number of training and validation samples\n",
        "num_train_samples = 2000\n",
        "num_validation_samples = 800\n",
        "\n",
        "# Set the number of epochs and batch size\n",
        "epochs = 5\n",
        "batch_size = 16\n",
        "\n",
        "# Load the InceptionV3 model without the top layer\n",
        "base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Freeze the base model layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Create a new model\n",
        "model = Sequential()\n",
        "\n",
        "# Add the base model as a layer\n",
        "model.add(base_model)\n",
        "\n",
        "# Add custom layers on top of the base model\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Preprocess the training and validation data\n",
        "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "validation_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    validation_data_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "\n",
        "# Train the model\n",
        "model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=num_train_samples // batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=num_validation_samples // batch_size)\n",
        "\n",
        "# Save the trained model\n",
        "model.save('dog_cat_classifier.h5')\n"
      ],
      "metadata": {
        "id": "peVGy9xb1Jna"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GPdjvT2h1MtK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}